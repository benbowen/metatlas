{
 "metadata": {
  "name": "",
  "signature": "sha256:055a0c9e81f01d0fd2dcc17921ac1013b1e9e2f66bd116dbfdbde692c8b9364c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Chapter 2.  What's in my sample"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Welcome to this introduction to the programmatic access capabilities for Metabolite Atlas. The full Github repository is available at https://github.com/benbowen/metatlas. \n",
      "\n",
      "Other resources can be found at the project's homepage: https://metatlas.nersc.gov/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'svg' \n",
      "from matplotlib import pyplot as plt\n",
      "import requests, json\n",
      "import numpy as np\n",
      "import sys\n",
      "import os\n",
      "sys.path.append( '/Users/bpb/Data/programming/MetaboliteAtlas/github/metatlas/' )\n",
      "import metatlas\n",
      "from bokeh.plotting import *\n",
      "output_notebook()\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Authenticate"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run the next block once to setup the csrf token for subsequent calls to the server.  Ensure that the password is never checked into the repository.  I think the token lasts for 12 hours."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# when ipython notbook releases update replace this block with getpass\n",
      "# NEVER CHECKIN THE USERINFO.TXT FILE TO THE REPO!!!!!\n",
      "userFile = '../userinfo.txt'\n",
      "client = metatlas.authenticateUser(userFile)\n",
      "\n",
      "# get an experiment ID\n",
      "experiments = metatlas.listMyExperiments(client)\n",
      "for experiment in experiments:\n",
      "        print experiment[u'name']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Get an experiment ID"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the previous block, if you logged in successfully a list of all experiments from the server will appear.  Filter that list of experiments to match your experiment name.  This gets the experiment UUID from the one you want from the list of experiment names.  We'll need the myExperimentID to find a file that we want to operate on."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### edit the myExperimentName string ####\n",
      "# myExperimentName = 'Soil_Particle_Metabolite_Interactions'\n",
      "# myExperimentName = 'CHCl3MeOHH2O_C1855_ACNIPAH2O_QTOF6520_KBL'\n",
      "myExperimentName = '20141003_MetAtlas_Demo'\n",
      "myExperimentID = filter( lambda x: x[u'name']==myExperimentName, experiments )[0][u'_id']\n",
      "print myExperimentID"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "share an experiment with another user"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metatlas = reload(metatlas)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# /api/experiment/<experiment_id>/share/\n",
      "# { \"user\": \"<username\", [or \"group\": \"<groupname>\"], \"perms\": [... list of perms (i.e. \"read\", \"write\", \"admin\")] } \n",
      "# Gives the specified user permissions for the experiment\n",
      "allUsers = ['alubbe']\n",
      "allPerms = [\"read\",\"write\"]\n",
      "r = metatlas.shareExperiments(allUsers,allPerms,client,myExperimentID)\n",
      "\n",
      "print r.content\n",
      "\n",
      "# https://metatlas.nersc.gov/api/experiment/53fe9ca408dbab407393fe19/share/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Get the list of files for an experiment"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Taking \"myExperimentID\" from the cell above, we can use that here to get all the files for that experiment.  This is stored in \"files\".  Print \"files\" and see all the runs.  I use a filter with a preffered file name specified in \"myFilename\" to get the run I want.  The pending status is also printed for each run:\n",
      "<ul>\n",
      "<li>pending = 0 means loaded or finished converting</li>\n",
      "<li>pending = 1 means pending or just uploaded</li>\n",
      "<li>pending = 2 means loading or in process of converting</li>\n",
      "</ul>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = 'https://metatlas.nersc.gov/api/experiment/%s' % myExperimentID\n",
      "r = client.get(url)\n",
      "files = json.loads(r.content)\n",
      "fileInfo = {'fid':[],'name':[],'status':[]};\n",
      "\n",
      "for i,myRun in enumerate(files[u'runs']):\n",
      "    splitPathToFile = os.path.split(myRun[u'in_file'])\n",
      "#     if (\"Control\" in splitPathToFile[1]) and not (\"Neg\" in splitPathToFile[1]):\n",
      "    print 'Num = %d; Pending = %d; FID = %s and NAME = \"%s\" ' %(i,myRun[u'pending'],myRun[u'_id'][u'file_id'],splitPathToFile[1])\n",
      "    if myRun[u'pending'] == 0:\n",
      "        fileInfo['fid'].append(myRun[u'_id'][u'file_id'])\n",
      "        fileInfo['name'].append(splitPathToFile[1])\n",
      "        fileInfo['status'].append(myRun[u'pending']) #only keep if status is 0\n",
      "pathYouWant = splitPathToFile[0] # TODO: we will have to see what this will do on a window's computer.  taking a linux path and using os.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metatlas = reload(metatlas)\n",
      "fileInfo = metatlas.groupFilesAcrossTwoDimensions(fileInfo)\n",
      "\n",
      "import pickle\n",
      "\n",
      "output = open('fileInfo.pkl', 'wb')\n",
      "\n",
      "# Pickle dictionary using protocol 0.\n",
      "pickle.dump(fileInfo, output)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Take the file you want and paste it below.  All the files should be on the same path; so the last path listed is fine.\n",
      "\n",
      "The block below will give you the SciDB array name and the RunID.  We'll need these variables in the block below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### edit the fileYouWant string ####\n",
      "fileYouWant = '140806_CAS16_POS.mzML'\n",
      "# fileYouWant = '02-a-tap-0-1.mzML'\n",
      "# fileYouWant = '140908_2_3_37_pos.mzML' #\n",
      "# fileYouWant = '140905_0_1_RT_neg.mzML'\n",
      "# fileYouWant = '140908_2_2_37_pos.mzML' #good\n",
      "# fileYouWant = '140905_0_4_RT_pos.mzML'\n",
      "myFilename = '%s/%s' % (pathYouWant, fileYouWant)\n",
      "myMatch = filter( lambda x: x[u'in_file']==myFilename and x[u'pending']==0, files[u'runs'] )[0][u'_id']\n",
      "myArray = myMatch[u'array_name']\n",
      "myRunID = myMatch[u'file_id']\n",
      "print myRunID"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define lists of the files that you want to study as groups\n",
      "blankFiles_pos = [10668, 10669, 10670] #extraction blank files positive mode\n",
      "mediaFiles_pos = [10673,10671,10675] #media controls in positive mode\n",
      "spentFiles_pos = [10672,10674,10676] #spent media files in positive mode\n",
      "qc_CAS16_Files_pos = [10684] #casette_16 of standards run as QCs\n",
      "qc_CAS17_Files_pos = [10686] #casette_17 of standards run as QCs\n",
      "export_fileIds = mediaFiles_pos + spentFiles_pos\n",
      "print export_fileIds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Defining the File Ids that we want to consider for our analysis. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import re\n",
      "# export_fileIds = []\n",
      "# print fileInfo['pos_groups'].keys()\n",
      "# for group in fileInfo['pos_groups']:\n",
      "#     if re.search('@23',group):\n",
      "#         export_fileIds = export_fileIds + fileInfo['pos_groups'][group]\n",
      "export_fileIds = fileInfo['fid']\n",
      "print export_fileIds\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Get the EICs for all files in the list \"export_fileIds\" for all compounds in your Atlas"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(dictData[u'compounds'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "metatlas = reload(metatlas)\n",
      "polarity = 1\n",
      "extraTime = 0.3\n",
      "data = []\n",
      "for i,compound in enumerate(dictData[u'compounds']):\n",
      "    try:\n",
      "        data.append(metatlas.getEICForCompounds(compound,myArray,export_fileIds,extraTime,client,polarity))\n",
      "        print i\n",
      "        print compound\n",
      "    except:\n",
      "        print i, \"failed\"\n",
      "        print compound\n",
      "        data.append([])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "export_filenames = []\n",
      "for i,myFile in enumerate(export_fileIds):\n",
      "    for j,fid in enumerate(fileInfo['fid']):\n",
      "        if fid == myFile:\n",
      "            export_filenames.append(fileInfo['name'][j].replace('mzML','png'))\n",
      "%config InlineBackend.figure_format = 'png' \n",
      "\n",
      "numCols = 4.\n",
      "\n",
      "nRows = int(np.ceil(len(dictData[u'compounds'][:])/numCols))\n",
      "\n",
      "    \n",
      "for j,myFile in enumerate(export_fileIds):\n",
      "    # j=1\n",
      "    # myFile = export_fileIds[1]\n",
      "    fig, ax = plt.subplots(nRows, int(numCols),figsize=(3.67*numCols,nRows * 4))\n",
      "    fig.subplots_adjust(bottom=0.0, left=0.0)\n",
      "    for i,a in enumerate(ax.flat):\n",
      "        if i<len(dictData[u'compounds']):\n",
      "            a.set_title(dictData[u'compounds'][i][u'name'])\n",
      "            try:\n",
      "                x1 = data[i][:,0][(data[i][:,2]==myFile)]\n",
      "                y1 = data[i][:,1][(data[i][:,2]==myFile)]\n",
      "                idx = np.argsort(x1)\n",
      "                x1 = x1[idx]\n",
      "                y1 = y1[idx]\n",
      "                if len(x1)>10:\n",
      "                    m = np.max(y1)\n",
      "                    y1 = y1 / m\n",
      "                    tempData = {'xdata':x1,'ydata':y1,'name':dictData[u'compounds'][i]['name'],'iMax':m}\n",
      "                    fitResult = metatlas.fitACompound(dictData[u'compounds'][i],tempData)\n",
      "                    metatlas.createChromatogramPlots(tempData,dictData[u'compounds'][i],fitResult,a)\n",
      "            except:\n",
      "                m = 1+1\n",
      "    fig.savefig(export_filenames[j])\n",
      "    fig.clear()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "5. Get an EIC or TIC"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the next blocks, we'll make a TIC.  If you use the standard internal standards, the m/z values below will be useful for debugging problematic runs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "D = 2.014102\n",
      "H = 1.007825\n",
      "C = 12\n",
      "N = 14.003074\n",
      "O = 15.994915\n",
      "proton = 1.007276\n",
      "# C6H10D4N2O2 + [H+]\n",
      "# C7H1D5O2 - [H+]\n",
      "lysine = C*6 + H*10 + D*4 + N*2 + O*2 + proton\n",
      "benzoicAcid = C*7 + H + D*5 + O*2 - proton\n",
      "print lysine\n",
      "print benzoicAcid"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "payload = {'L':1,'P':1,'arrayname':myArray,'fileid':qc_CAS17_Files_pos[0],\n",
      "           'max_mz':151.139,'min_mz':151.135,\n",
      "           'nsteps':20000,'queryType':'XICofFile'}\n",
      "url = 'https://metatlas.nersc.gov/api/run'\n",
      "\n",
      "r = client.get(url,params=payload)\n",
      "data = np.asarray(json.loads(r.content))\n",
      "plt.plot(data[:,0],data[:,1])\n",
      "# plt.xlim(5,15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fileInfo ['pos_groups'].keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get multiple files\n",
      "files_I_want = spentFiles_pos+mediaFiles_pos+blankFiles_pos+qc_CAS16_Files_pos+qc_CAS17_Files_pos\n",
      "# files_I_want = fileInfo ['pos_groups'][u'2@23'][:]\n",
      "# groups = fileInfo ['groups'].keys()\n",
      "# files_I_want = []\n",
      "# for group in groups:\n",
      "#     files_I_want = files_I_want + fileInfo['groups'][group]\n",
      "# files_I_want = qc_CAS17_Files_pos+qc_CAS16_Files_pos\n",
      "myList = ','.join(map(str, files_I_want))\n",
      "payload = {'L':1,'P':1,'arrayname':myArray,'fileidlist':myList,\n",
      "          'max_mz':900,'min_mz':100,\n",
      "          'min_rt':5,'max_rt':17,\n",
      "          'nsteps':20000,'queryType':'XICofFile_mf'}\n",
      "url = 'https://metatlas.nersc.gov/api/run'\n",
      "r = client.get(url,params=payload)\n",
      "data = np.asarray(json.loads(r.content))\n",
      "\n",
      "for myFile in files_I_want:\n",
      "    x1 = data[:,0][(data[:,2]==myFile)]\n",
      "    y1 = data[:,1][(data[:,2]==myFile)]\n",
      "    idx = np.argsort(x1)\n",
      "    plt.plot(x1[idx],y1[idx])\n",
      "plt.xlabel('Time (min)')\n",
      "plt.ylabel('TIC Intensity (au)')\n",
      "# plt.xlim(5,15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Select a Metabolite Atlas From the System"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get a list of all method specific metabolite atlases in the system\n",
      "# GET /api/dict/\n",
      "url = 'https://metatlas.nersc.gov/api/dict/'\n",
      "r = client.get(url)\n",
      "allAtlases = json.loads(r.text)\n",
      "for atlas in allAtlases:\n",
      "    atlas_str = '%s has an atlas named %s has the ID: %s' % (atlas[u'creator'],atlas['name'], atlas['_id'])\n",
      "    print atlas_str"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the entries for a specific dictionary\n",
      "# GET /api/dict/<dict_id>/\n",
      "dictId = '5433367e762640542f846835'\n",
      "url = 'https://metatlas.nersc.gov/api/dict/%s/' % dictId\n",
      "r = client.get(url)\n",
      "dictData = json.loads(r.text)\n",
      "print dictData"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Adds the specified compound dictionary to the experiment\n",
      "# POST\t/api/experiment/<experiment_id>/dict/\t{ \"dict_id\": <dict_id_to_be_added> } JSON\n",
      "url = 'https://metatlas.nersc.gov/api/experiment/%s/dict/' % myExperimentID\n",
      "payload = {\"dict_id\":dictId}\n",
      "r = client.post(url, data=json.dumps(payload))\n",
      "print(r.text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#add compounds to an atlas from a well formated spreadsheet\n",
      "import csv\n",
      "filename = 'example_metatlas_spreadsheet.txt'\n",
      "with open(filename,'rU') as file_object:\n",
      "    payload = list(csv.DictReader(file_object, dialect='excel-tab'))\n",
      "\n",
      "url = 'https://metatlas.nersc.gov/api/dict/%s/' % dictId\n",
      "r = client.post(url, data=json.dumps(payload))\n",
      "print(r.text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#add compounds to an atlas from a well formated spreadsheet that are new and\n",
      "#update any that were already there, but have changed\n",
      "import csv\n",
      "# filename = 'example_metatlas_spreadsheet.txt'\n",
      "filename = 'ChlamyLipids_pos.txt'\n",
      "with open(filename,'rU') as file_object:\n",
      "    sheetData = list(csv.DictReader(file_object, dialect='excel-tab'))\n",
      "\n",
      "\n",
      "url = 'https://metatlas.nersc.gov/api/dict/%s/' % dictId\n",
      "r = client.get(url)\n",
      "dictData = json.loads(r.text)\n",
      "\n",
      "for compound in sheetData:\n",
      "    print compound\n",
      "    cID = filter( lambda x: x[u'name']==compound['name'], dictData[u'compounds'])\n",
      "    if not cID:\n",
      "        # a new entry is created if that compound name doesn't exist\n",
      "        url = 'https://metatlas.nersc.gov/api/dict/%s/' % dictId\n",
      "        r = client.post(url, data=json.dumps(compound))\n",
      "#         print(r.text)\n",
      "    else:\n",
      "        # edit the entry if it already exists\n",
      "        url = 'https://metatlas.nersc.gov/api/compound/%s/' % cID[0][u'_id']\n",
      "        r = client.patch(url, data=json.dumps(compound))\n",
      "#         print(r.text)\n",
      "url = 'https://metatlas.nersc.gov/api/dict/%s/' % dictId\n",
      "r = client.get(url)\n",
      "dictData = json.loads(r.text)        \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# export an atlas\n",
      "myList = ['name','pubchem_id','formula','neutral_mass','mz','mz_threshold','adducts','rt_max','rt_min','rt_peak']\n",
      "import csv\n",
      "filename = 'atlas_export.txt'\n",
      "fid = open(filename,'wb')\n",
      "for listItem in myList:\n",
      "    fid.write('%s\\t' % listItem)\n",
      "fid.write('\\n')\n",
      "for i,compound in enumerate(dictData[u'compounds']):\n",
      "    for listItem in myList:\n",
      "        fid.write('%s\\t' % compound[listItem])\n",
      "    fid.write('\\n')\n",
      "fid.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Optimization block to estimate rtPeak and rt bounds"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following block takes a good guess from a user and users non-linear least-squares optimization to provide a best-fit of rt_Peak, rt_min, and rt_max.  In addition it integrates a deconvoluted peak areea.  Make sure you run the block above to get \"data\", \"rtPeak\", \"rtMin\", \"rtMax\".  The vector \"c\" produced by this block, produces the best fit values for peak area, rtPeak, rtMin, and rtMax respectively."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define the fitting function and the error function to be used in the optimization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$Intensity(t) = PeakArea * \\frac{1}{2}e^{-(t-rtPeak)^2/(rtWidth^2)}$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In our case, we don't assume that the chromatogram is symetrical in time.  Therefore, we solve the problem from rtPeak forward in time using one width variable, \"p[1]\".  The solution is also solved less than rtPeak using another width variable, \"p[2]\"."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the error function, lets give the error a weight based on the normal probability distribution.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$E(t) = OriginalData(t) - Intensity(t) * \\frac{1}{2}e^{-(t-originalRTPeak)^2/(0.1^2)}$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For situations where the rtWidth on the left or right side becomes large, we blow the error up to 1e100."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metatlas = reload(metatlas)\n",
      "polarity = 1 # set to 0 for negative mode and 1 for positive mode\n",
      "# compound = dictData[u'compounds'][4] #leucine\n",
      "compound = dictData[u'compounds'][9] #proline\n",
      "print compound\n",
      "data = metatlas.getEICForCompound(compound,myArray,qc_CAS17_Files_pos[0],0.5,client,polarity)\n",
      "# data = metatlas.getEICForCompound(compound,myArray,myRunID,0.5,client,polarity)\n",
      "\n",
      "fitResult = metatlas.fitACompound(compound,data)\n",
      "print fitResult\n",
      "print compound[u'name']\n",
      "\n",
      "fig, ax = plt.subplots(1, 1,figsize=(5,5))\n",
      "metatlas.createChromatogramPlots(data,compound,fitResult,ax)\n",
      "\n",
      "print 'Modeled peak area is %d from an asymmetric gaussian.' % (np.sum(data['iMax']*metatlas.fitfunc(fitResult, data['xdata'])))\n",
      "print 'Old rt_peak was at %s minutes and the modeled peak is at %5.3f minutes.' % (compound[u'rt_peak'],fitResult[1])\n",
      "print 'Old rt_min was at %s minutes and the modeled rt_min is at %5.3f minutes.' % (compound[u'rt_min'],fitResult[1]-2*fitResult[3])\n",
      "print 'Old rt_max was at %s minutes and the modeled rt_max is at %5.3f minutes.' % (compound[u'rt_max'],fitResult[1]+2*fitResult[2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nRows = int(np.ceil(len(dictData[u'compounds'][:])/3.))\n",
      "fig, ax = plt.subplots(nRows, 3,figsize=(11,nRows * 4))\n",
      "fig.subplots_adjust(bottom=0.0, left=0.0)\n",
      "outResults = np.zeros((len(dictData[u'compounds']),4))\n",
      "polarity = 1\n",
      "for i,a in enumerate(ax.flat):\n",
      "    data = metatlas.getEICForCompound(dictData[u'compounds'][i],myArray,myRunID,0.5,client,polarity)\n",
      "    if len(data['xdata'])>10:\n",
      "        fitResult = metatlas.fitACompound(dictData[u'compounds'][i],data)\n",
      "        metatlas.createChromatogramPlots(data,dictData[u'compounds'][i],fitResult,a)\n",
      "        outResults[i,:] = fitResult\n",
      "    else:\n",
      "        a.set_title(dictData[u'compounds'][i][u'name'])\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# fig.savefig('chromatograms.eps')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig.savefig('chromatograms.pdf',bbox_inches='tight')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Export the values from the curve fits\n",
      "# name\tpubchem_id\tformula\tneutral_mass\tmz\tmz_threshold\tadducts\trt_max\trt_min\trt_peak\n",
      "import csv\n",
      "filename = 'annotations_updated.txt'\n",
      "fid = open(filename,'wb')\n",
      "fid.write('%s\\t' % 'compound')\n",
      "fid.write('Area\\trtPeak\\tsig1\\tsig2\\n')\n",
      "for i,compound in enumerate(dictData[u'compounds']):\n",
      "    fid.write('%s\\t' % compound[u'name'])\n",
      "    for result in outResults[i,:]:\n",
      "        fid.write('%5.5f\\t' % result)\n",
      "    fid.write('\\n')\n",
      "fid.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a new entry for a dictionary\n",
      "# POST /api/dict/<dict_id>/\n",
      "# payload = [{\"adducts\":\"H+\",\"formula\":\"C6H13NO2\",\"name\":\"Isoleucine\",\"rt_max\":8.6,\"rt_min\":3,\"rt_peak\":7.5,\"mz\":132.101876,\"mz_threshold\":5,\"neutral_mass\":131.0946,\"pubchem_id\":0}]\n",
      "# payload = [{\"adducts\":\"H+\",\"formula\":\"C6H13NO2\",\"name\":\"Leucine\",\"rt_max\":8.6,\n",
      "#             \"rt_min\":8.2,\"rt_peak\":8.3,\"mz\":132.101876,\"mz_threshold\":5,\n",
      "#             \"neutral_mass\":131.0946,\"pubchem_id\":0}]\n",
      "\n",
      "payload = [{'adducts': 'H+', 'name': 'RBRB 99.0926@7.8', 'rt_max': '9.801327045', 'mz_threshold': '20', 'pubchem_id': '0', 'rt_min': '5.801327045', 'formula': '', 'rt_peak': '7.801327045', 'neutral_mass': '', 'mz': '99.0926'}]\n",
      "url = 'https://metatlas.nersc.gov/api/dict/%s/' % dictId\n",
      "r = client.post(url, data=json.dumps(payload))\n",
      "print(r.text)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Edit a compound in a dictionary\n",
      "# PATCH /api/compound/<compound_id>/\n",
      "\n",
      "# compoundId = '5410a27f7626405077ecc613' # for isoleucine\n",
      "compoundId = '541a299876264079fddaa64e' # for leucine\n",
      "# payload = {\"pubchem_id\":10}\n",
      "# payload = {\"rt_peak\": 7.917,\"rt_max\": 8.172,\"rt_min\":7.757}\n",
      "payload = {\"rt_peak\": 8.289,\"rt_max\": 8.541,\"rt_min\":8.141}\n",
      "url = 'https://metatlas.nersc.gov/api/compound/%s/' % compoundId\n",
      "r = client.patch(url, data=json.dumps(payload))\n",
      "print(r.text)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Gets all the compound dictionaries associated with the experiement\n",
      "# GET\t/api/experiment/<experiment_id>/dict/\t\t\n",
      "url = 'https://metatlas.nersc.gov/api/experiment/%s/dict/' % myExperimentID\n",
      "r = client.get(url)\n",
      "print r.text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Adds the specified compound dictionary to the experiment\n",
      "# POST\t/api/experiment/<experiment_id>/dict/\t{ \"dict_id\": <dict_id_to_be_added> } JSON\n",
      "url = 'https://metatlas.nersc.gov/api/experiment/%s/dict/' % myExperimentID\n",
      "payload = {\"dict_id\":dictId}\n",
      "r = client.post(url, data=json.dumps(payload))\n",
      "print(r.text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Gets the dictionaries associated with the run\n",
      "# GET\t/api/metadata/<array_name>/<file_id>/dict/\n",
      "url = 'https://metatlas.nersc.gov/api/metadata/%s/%s/dict/' % ( myArray, myRunID )\n",
      "print url\n",
      "r = client.get(url)\n",
      "print r.text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# /api/metadata/<array_name>/<file_id>/dict/<dict_index>/\n",
      "# Gets details (incl. compounds) about a specified dictionary\n",
      "url = 'https://metatlas.nersc.gov/api/metadata/%s/%s/dict/0' % ( myArray, myRunID )\n",
      "print url\n",
      "r = client.get(url)\n",
      "print r.text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# /api/metadata/<array_name>/<file_id>/dict/<dict_index>/<compound_id>/\t{ \"<updated_val_name>\": <updated_val> ... } JSON\n",
      "# Updates the run level compound with the values specified"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# PUT /api/metadata/<array_name>/<file_id>/dict/<dict_index>/<compound_id>/reset/\n",
      "# Reverts the compound's fields to those of the parent (experiment level) compound dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# DELETE /api/metadata/<array_name>/<file_id>/dict/<dict_index>/<compound_id>/\n",
      "# Removes the compound from the run level compound dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# export the peak areas for a file using the dictionary\n",
      "# /api/metadata/<array_name>/<file_id>/export/\n",
      "# url = 'https://metatlas.nersc.gov/api/metadata/%s/%s/export/0' % ( myArray, myRunID )\n",
      "# print url\n",
      "# r = client.get(url)\n",
      "# print r.text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TOOLS=\"pan,wheel_zoom,box_zoom,reset,hover\"\n",
      "\n",
      "color_cycle=['red', 'green', 'blue', 'black','cyan','magenta','yellow']\n",
      "hold()\n",
      "figure()\n",
      "for datum in data:\n",
      "    for i,myFile in enumerate(export_fileIds):\n",
      "        x1 = datum[:,0][(datum[:,2]==myFile)]\n",
      "        y1 = datum[:,1][(datum[:,2]==myFile)]\n",
      "        idx = np.argsort(x1)\n",
      "        line(x1[idx],y1[idx], \n",
      "             plot_width=1000, plot_height=500,\n",
      "             line_color=color_cycle[i],\n",
      "             title='Chromatograms',\n",
      "             x_axis_label='Time (minutes)',\n",
      "             y_axis_label='Intensity')\n",
      "\n",
      "for i,myFile in enumerate(export_fileIds):\n",
      "    for j,fid in enumerate(fileInfo['fid']):\n",
      "        if fid == myFile:\n",
      "            scatter(0,0,line_color=color_cycle[i],\n",
      "                    fill_color=color_cycle[i],legend=fileInfo['name'][j])\n",
      "            \n",
      "show()\n",
      "hold('false')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "export_filenames = []\n",
      "for i,myFile in enumerate(export_fileIds):\n",
      "    for j,fid in enumerate(fileInfo['fid']):\n",
      "        if fid == myFile:\n",
      "            export_filenames.append(fileInfo['name'][j])\n",
      "filename = 'output.txt'\n",
      "fid = open(filename,'wb')\n",
      "fid.write('%s\\t' % 'compound')\n",
      "for filename in export_filenames:\n",
      "    fid.write('%s\\t' % filename)\n",
      "fid.write('\\n')\n",
      "for i,datum in enumerate(data):\n",
      "    fid.write('%s\\t' % dictData[u'compounds'][i]['name'])\n",
      "    for j,myFile in enumerate(export_fileIds):\n",
      "        try:\n",
      "            x1 = datum[:,0][(datum[:,2]==myFile)]\n",
      "            y1 = datum[:,1][(datum[:,2]==myFile)]\n",
      "            fid.write('%5.2f\\t' % sum(y1))\n",
      "        except:\n",
      "            fid.write('%5.2f\\t' % 0)\n",
      "    fid.write('\\n')\n",
      "fid.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}