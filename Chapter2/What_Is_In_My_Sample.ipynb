{
 "metadata": {
  "name": "",
  "signature": "sha256:3c757c1136498964852488fe922bd2faead239183d0202194c7bd077c1ba467e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Chapter 2.  What's in my sample"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Welcome to this introduction to the programmatic access capabilities for Metabolite Atlas. The full Github repository is available at https://github.com/benbowen/metatlas. \n",
      "\n",
      "Other resources can be found at the project's homepage: https://metatlas.nersc.gov/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'svg' \n",
      "from matplotlib import pyplot as plt\n",
      "import requests, json\n",
      "import numpy as np\n",
      "import sys\n",
      "import os\n",
      "sys.path.append( '/Users/bpb/Data/programming/MetaboliteAtlas/github/metatlas/' )\n",
      "import metatlas\n",
      "from bokeh.plotting import *\n",
      "output_notebook()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "1. Authenticate"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run the next block once to setup the csrf token for subsequent calls to the server.  Ensure that the password is never checked into the repository.  I think the token lasts for 12 hours."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "authURL = 'https://metatlas.nersc.gov/client/login/'\n",
      "\n",
      "# getpass\n",
      "# NEVER CHECKIN THE USERINFO.TXT FILE TO THE REPO!!!!!\n",
      "file = open('../userinfo.txt', 'r')\n",
      "userID = file.readline()[:-1]\n",
      "userPassword = file.readline()[:-1]\n",
      "file.close()\n",
      "\n",
      "client = requests.Session()\n",
      "# Retrieve the CSRF token first\n",
      "client.get(authURL)  # sets cookie\n",
      "csrftoken = client.cookies['csrftoken']\n",
      "login_data = dict(username=userID, password=userPassword, csrfmiddlewaretoken=csrftoken, next='/')\n",
      "r = client.post(authURL, data=login_data, headers=dict(Referer=authURL))\n",
      "print r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "2.  Get an experiment ID"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the following block, get a list of all experiments from the server.  Filter that list of experiments to match your experiment name."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get an experiment ID\n",
      "url = 'https://metatlas.nersc.gov/api/experiment'\n",
      "r = client.get(url)\n",
      "experiments = json.loads(r.content)\n",
      "for experiment in experiments:\n",
      "    print experiment[u'name']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Get the experiment UUID from the one you want from the list of experiment names.  We'll need the myExperimentID to find a file that we want to operate on."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### edit the myExperimentName string ####\n",
      "# myExperimentName = 'Soil_Particle_Metabolite_Interactions'\n",
      "myExperimentName = '20141003_MetAtlas_Demo'\n",
      "myExperimentID = filter( lambda x: x[u'name']==myExperimentName, experiments )[0][u'_id']\n",
      "print myExperimentID"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "share an experiment with another user"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# /api/experiment/<experiment_id>/share/\n",
      "# { \"user\": \"<username\", [or \"group\": \"<groupname>\"], \"perms\": [... list of perms (i.e. \"read\", \"write\", \"admin\")] } \n",
      "# Gives the specified user permissions for the experiment\n",
      "allUsers = ['username']\n",
      "for aUser in allUsers:\n",
      "    payload = {\"user\":aUser,\"perms\":[\"read\",\"write\"]}\n",
      "    sendData=json.dumps(payload)\n",
      "    # print sendData\n",
      "    url = 'https://metatlas.nersc.gov/api/experiment/%s/share/' % myExperimentID\n",
      "    # print url\n",
      "    r = client.post(url, data=sendData)\n",
      "    print r.content\n",
      "    # f = open('error.html','w')\n",
      "    # f.write(r.content)\n",
      "    # f.close()\n",
      "\n",
      "# https://metatlas.nersc.gov/api/experiment/53fe9ca408dbab407393fe19/share/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "3. Get the list of files for an experiment"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Taking \"myExperimentID\" from the cell above, we can use that here to get all the files for that experiment.  This is stored in \"files\".  Print \"files\" and see all the runs.  I use a filter with a preffered file name specified in \"myFilename\" to get the run I want."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = 'https://metatlas.nersc.gov/api/experiment/%s' % myExperimentID\n",
      "r = client.get(url,data=login_data)\n",
      "files = json.loads(r.content)\n",
      "fileInfo = {'fid':[],'name':[]};\n",
      "\n",
      "for i,myRun in enumerate(files[u'runs']):\n",
      "    splitPathToFile = os.path.split(myRun[u'in_file'])\n",
      "#     if (\"Control\" in splitPathToFile[1]) and not (\"Neg\" in splitPathToFile[1]):\n",
      "    print 'FID = %s and NAME = \"%s\" ' %(myRun[u'_id'][u'file_id'],splitPathToFile[1])\n",
      "    fileInfo['fid'].append(myRun[u'_id'][u'file_id'])\n",
      "    fileInfo['name'].append(splitPathToFile[1])\n",
      "pathYouWant = splitPathToFile[0] # TODO: we will have to see what this will do on a window's computer.  taking a linux path and using os."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Take the file you want and paste it below.  All the files should be on the same path; so the last path listed is fine.\n",
      "\n",
      "The block below will give you the SciDB array name and the RunID.  We'll need these variables in the block below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### edit the fileYouWant string ####\n",
      "# fileYouWant = '140808_1_RCH2_pos.mzML'\n",
      "fileYouWant = '140718 M9C Rep2 Control.mzML'\n",
      "myFilename = '%s/%s' % (pathYouWant, fileYouWant)\n",
      "myMatch = filter( lambda x: x[u'in_file']==myFilename, files[u'runs'] )[0][u'_id']\n",
      "myArray = myMatch[u'array_name']\n",
      "myRunID = myMatch[u'file_id']\n",
      "print myRunID"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define lists of the files that you want to study as groups\n",
      "blankFiles_pos = [10668, 10669, 10670] #extraction blank files positive mode\n",
      "mediaFiles_pos = [10673,10671,10675] #media controls in positive mode\n",
      "spentFiles_pos = [10672,10674,10676] #spent media files in positive mode\n",
      "qc_CAS16_Files_pos = [10684] #casette_16 of standards run as QCs\n",
      "qc_CAS17_Files_pos = [10686] #casette_17 of standards run as QCs\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "5. Get an EIC or TIC"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the next blocks, we'll make a TIC"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "payload = {'L':1,'P':1,'arrayname':myArray,'fileid':myRunID,\n",
      "           'max_mz':10000,'min_mz':1,\n",
      "           'nsteps':20000,'queryType':'XICofFile'}\n",
      "url = 'https://metatlas.nersc.gov/api/run'\n",
      "r = client.get(url,params=payload)\n",
      "data = np.asarray(json.loads(r.content))\n",
      "plt.plot(data[:,0],data[:,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get multiple files\n",
      "files_I_want = spentFiles_pos+mediaFiles_pos+blankFiles_pos+qc_CAS16_Files_pos+qc_CAS17_Files_pos\n",
      "# files_I_want = qc_CAS17_Files_pos+qc_CAS16_Files_pos\n",
      "myList = ','.join(map(str, files_I_want))\n",
      "payload = {'L':1,'P':1,'arrayname':myArray,'fileidlist':myList,\n",
      "          'max_mz':152.1,'min_mz':152,\n",
      "          'min_rt':0.01,'max_rt':40,\n",
      "          'nsteps':20000,'queryType':'XICofFile_mf'}\n",
      "url = 'https://metatlas.nersc.gov/api/run'\n",
      "r = client.get(url,params=payload)\n",
      "data = np.asarray(json.loads(r.content))\n",
      "\n",
      "for myFile in files_I_want:\n",
      "    x1 = data[:,0][(data[:,2]==myFile)]\n",
      "    y1 = data[:,1][(data[:,2]==myFile)]\n",
      "    idx = np.argsort(x1)\n",
      "    plt.plot(x1[idx],y1[idx])\n",
      "plt.xlabel('Time (min)')\n",
      "plt.ylabel('TIC Intensity (au)')\n",
      "# plt.xlim(5,15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get a list of all method specific metabolite atlases in the system\n",
      "# GET /api/dict/\n",
      "url = 'https://metatlas.nersc.gov/api/dict/'\n",
      "r = client.get(url)\n",
      "allAtlases = json.loads(r.text)\n",
      "for atlas in allAtlases:\n",
      "    atlas_str = '%s has an atlas named %s has the ID: %s' % (atlas[u'creator'],atlas['name'], atlas['_id'])\n",
      "    print atlas_str"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the entries for a specific dictionary\n",
      "# GET /api/dict/<dict_id>/\n",
      "dictId = '5433367e762640542f846835'\n",
      "url = 'https://metatlas.nersc.gov/api/dict/%s/' % dictId\n",
      "r = client.get(url)\n",
      "dictData = json.loads(r.text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Adds the specified compound dictionary to the experiment\n",
      "# POST\t/api/experiment/<experiment_id>/dict/\t{ \"dict_id\": <dict_id_to_be_added> } JSON\n",
      "url = 'https://metatlas.nersc.gov/api/experiment/%s/dict/' % myExperimentID\n",
      "payload = {\"dict_id\":dictId}\n",
      "r = client.post(url, data=json.dumps(payload))\n",
      "print(r.text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#add compounds to an atlas from a well formated spreadsheet\n",
      "import csv\n",
      "# filename = 'example_metatlas_spreadsheet.txt'\n",
      "filename = 'YE_Baran_Pos_metatlas_spreadsheet.txt'\n",
      "with open(filename,'rU') as file_object:\n",
      "    payload = list(csv.DictReader(file_object, dialect='excel-tab'))\n",
      "\n",
      "url = 'https://metatlas.nersc.gov/api/dict/%s/' % dictId\n",
      "r = client.post(url, data=json.dumps(payload))\n",
      "print(r.text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Optimization block to estimate rtPeak and rt bounds"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following block takes a good guess from a user and users non-linear least-squares optimization to provide a best-fit of rt_Peak, rt_min, and rt_max.  In addition it integrates a deconvoluted peak areea.  Make sure you run the block above to get \"data\", \"rtPeak\", \"rtMin\", \"rtMax\".  The vector \"c\" produced by this block, produces the best fit values for peak area, rtPeak, rtMin, and rtMax respectively."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define the fitting function and the error function to be used in the optimization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$Intensity(t) = PeakArea * \\frac{1}{2}e^{-(t-rtPeak)^2/(rtWidth^2)}$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In our case, we don't assume that the chromatogram is symetrical in time.  Therefore, we solve the problem from rtPeak forward in time using one width variable, \"p[1]\".  The solution is also solved less than rtPeak using another width variable, \"p[2]\"."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the error function, lets give the error a weight based on the normal probability distribution.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$E(t) = OriginalData(t) - Intensity(t) * \\frac{1}{2}e^{-(t-originalRTPeak)^2/(0.1^2)}$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For situations where the rtWidth on the left or right side becomes large, we blow the error up to 1e100."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metatlas = reload(metatlas)\n",
      "\n",
      "compound = dictData[u'compounds'][0] #leucine\n",
      "# compound = dictData[u'compounds'][9] #proline\n",
      "print compound\n",
      "# data = metatlas.getEICForCompound(compound,myArray,qc_CAS17_Files_pos[0],0.5,client)\n",
      "data = metatlas.getEICForCompound(compound,myArray,myRunID,0.5,client)\n",
      "\n",
      "fitResult = metatlas.fitACompound(compound,data)\n",
      "print fitResult\n",
      "print compound[u'name']\n",
      "\n",
      "fig, ax = plt.subplots(1, 1,figsize=(5,5))\n",
      "metatlas.createChromatogramPlots(data,compound,fitResult,ax)\n",
      "\n",
      "print 'Modeled peak area is %d from an asymmetric gaussian.' % (np.sum(data['iMax']*metatlas.fitfunc(fitResult, data['xdata'])))\n",
      "print 'Old rt_peak was at %s minutes and the modeled peak is at %5.3f minutes.' % (compound[u'rt_peak'],fitResult[1])\n",
      "print 'Old rt_min was at %s minutes and the modeled rt_min is at %5.3f minutes.' % (compound[u'rt_min'],fitResult[1]-2*fitResult[3])\n",
      "print 'Old rt_max was at %s minutes and the modeled rt_max is at %5.3f minutes.' % (compound[u'rt_max'],fitResult[1]+2*fitResult[2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nRows = int(np.ceil(len(dictData[u'compounds'][:])/3))\n",
      "fig, ax = plt.subplots(nRows, 3,figsize=(11,nRows * 4))\n",
      "fig.subplots_adjust(bottom=0.0, left=0.0)\n",
      "outResults = np.zeros((len(dictData[u'compounds']),4))\n",
      "for i,a in enumerate(ax.flat):\n",
      "    data = metatlas.getEICForCompound(dictData[u'compounds'][i],myArray,mediaFiles_pos[0],0.5,client)\n",
      "    if len(data['xdata'])>10:\n",
      "        fitResult = metatlas.fitACompound(dictData[u'compounds'][i],data)\n",
      "        metatlas.createChromatogramPlots(data,dictData[u'compounds'][i],fitResult,a)\n",
      "        outResults[i,:] = fitResult\n",
      "    else:\n",
      "        a.set_title(dictData[u'compounds'][i][u'name'])\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# fig.savefig('chromatograms.eps')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig.savefig('chromatograms.pdf',bbox_inches='tight')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Export the values from the curve fits\n",
      "import csv\n",
      "filename = 'annotations_bpb_updated.txt'\n",
      "fid = open(filename,'wb')\n",
      "fid.write('%s\\t' % 'compound')\n",
      "fid.write('Area\\trtPeak\\tsig1\\tsig2\\n')\n",
      "for i,compound in enumerate(dictData[u'compounds']):\n",
      "    fid.write('%s\\t' % compound[u'name'])\n",
      "    for result in outResults[i,:]:\n",
      "        fid.write('%5.5f\\t' % result)\n",
      "    fid.write('\\n')\n",
      "fid.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a new entry for a dictionary\n",
      "# POST /api/dict/<dict_id>/\n",
      "# payload = [{\"adducts\":\"H+\",\"formula\":\"C6H13NO2\",\"name\":\"Isoleucine\",\"rt_max\":8.6,\"rt_min\":3,\"rt_peak\":7.5,\"mz\":132.101876,\"mz_threshold\":5,\"neutral_mass\":131.0946,\"pubchem_id\":0}]\n",
      "# payload = [{\"adducts\":\"H+\",\"formula\":\"C6H13NO2\",\"name\":\"Leucine\",\"rt_max\":8.6,\n",
      "#             \"rt_min\":8.2,\"rt_peak\":8.3,\"mz\":132.101876,\"mz_threshold\":5,\n",
      "#             \"neutral_mass\":131.0946,\"pubchem_id\":0}]\n",
      "\n",
      "payload = [{'adducts': 'H+', 'name': 'RBRB 99.0926@7.8', 'rt_max': '9.801327045', 'mz_threshold': '20', 'pubchem_id': '0', 'rt_min': '5.801327045', 'formula': '', 'rt_peak': '7.801327045', 'neutral_mass': '', 'mz': '99.0926'}]\n",
      "url = 'https://metatlas.nersc.gov/api/dict/%s/' % dictId\n",
      "r = client.post(url, data=json.dumps(payload))\n",
      "print(r.text)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#add compounds to an atlas from a well formated spreadsheet that are new and\n",
      "#update any that were already there, but have changed\n",
      "import csv\n",
      "# filename = 'example_metatlas_spreadsheet.txt'\n",
      "filename = 'YE_Baran_Pos_metatlas_spreadsheet.txt'\n",
      "with open(filename,'rU') as file_object:\n",
      "    sheetData = list(csv.DictReader(file_object, dialect='excel-tab'))\n",
      "\n",
      "\n",
      "url = 'https://metatlas.nersc.gov/api/dict/%s/' % dictId\n",
      "r = client.get(url)\n",
      "dictData = json.loads(r.text)\n",
      "\n",
      "for compound in sheetData[:2]:\n",
      "    print compound\n",
      "    cID = filter( lambda x: x[u'name']==compound['name'], dictData[u'compounds'])\n",
      "    if not cID:\n",
      "        # a new entry is created if that compound name doesn't exist\n",
      "        url = 'https://metatlas.nersc.gov/api/dict/%s/' % dictId\n",
      "        r = client.post(url, data=json.dumps(compound))\n",
      "#         print(r.text)\n",
      "    else:\n",
      "        # edit the entry if it already exists\n",
      "        url = 'https://metatlas.nersc.gov/api/compound/%s/' % cID[0][u'_id']\n",
      "        r = client.patch(url, data=json.dumps(compound))\n",
      "#         print(r.text)\n",
      "url = 'https://metatlas.nersc.gov/api/dict/%s/' % dictId\n",
      "r = client.get(url)\n",
      "dictData = json.loads(r.text)        \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Edit a compound in a dictionary\n",
      "# PATCH /api/compound/<compound_id>/\n",
      "\n",
      "# compoundId = '5410a27f7626405077ecc613' # for isoleucine\n",
      "compoundId = '541a299876264079fddaa64e' # for leucine\n",
      "# payload = {\"pubchem_id\":10}\n",
      "# payload = {\"rt_peak\": 7.917,\"rt_max\": 8.172,\"rt_min\":7.757}\n",
      "payload = {\"rt_peak\": 8.289,\"rt_max\": 8.541,\"rt_min\":8.141}\n",
      "url = 'https://metatlas.nersc.gov/api/compound/%s/' % compoundId\n",
      "r = client.patch(url, data=json.dumps(payload))\n",
      "print(r.text)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Gets all the compound dictionaries associated with the experiement\n",
      "# GET\t/api/experiment/<experiment_id>/dict/\t\t\n",
      "url = 'https://metatlas.nersc.gov/api/experiment/%s/dict/' % myExperimentID\n",
      "r = client.get(url)\n",
      "print r.text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Adds the specified compound dictionary to the experiment\n",
      "# POST\t/api/experiment/<experiment_id>/dict/\t{ \"dict_id\": <dict_id_to_be_added> } JSON\n",
      "url = 'https://metatlas.nersc.gov/api/experiment/%s/dict/' % myExperimentID\n",
      "payload = {\"dict_id\":dictId}\n",
      "r = client.post(url, data=json.dumps(payload))\n",
      "print(r.text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Gets the dictionaries associated with the run\n",
      "# GET\t/api/metadata/<array_name>/<file_id>/dict/\n",
      "url = 'https://metatlas.nersc.gov/api/metadata/%s/%s/dict/' % ( myArray, myRunID )\n",
      "print url\n",
      "r = client.get(url)\n",
      "print r.text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# /api/metadata/<array_name>/<file_id>/dict/<dict_index>/\n",
      "# Gets details (incl. compounds) about a specified dictionary\n",
      "url = 'https://metatlas.nersc.gov/api/metadata/%s/%s/dict/0' % ( myArray, myRunID )\n",
      "print url\n",
      "r = client.get(url)\n",
      "print r.text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# /api/metadata/<array_name>/<file_id>/dict/<dict_index>/<compound_id>/\t{ \"<updated_val_name>\": <updated_val> ... } JSON\n",
      "# Updates the run level compound with the values specified"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# PUT /api/metadata/<array_name>/<file_id>/dict/<dict_index>/<compound_id>/reset/\n",
      "# Reverts the compound's fields to those of the parent (experiment level) compound dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# DELETE /api/metadata/<array_name>/<file_id>/dict/<dict_index>/<compound_id>/\n",
      "# Removes the compound from the run level compound dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# export the peak areas for a file using the dictionary\n",
      "# /api/metadata/<array_name>/<file_id>/export/\n",
      "# url = 'https://metatlas.nersc.gov/api/metadata/%s/%s/export/0' % ( myArray, myRunID )\n",
      "# print url\n",
      "# r = client.get(url)\n",
      "# print r.text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "export_fileIds = mediaFiles_pos + spentFiles_pos\n",
      "print export_fileIds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metatlas = reload(metatlas)\n",
      "data = []\n",
      "for i,compound in enumerate(dictData[u'compounds']):\n",
      "    data.append(metatlas.getEICForCompounds(compound,myArray,export_fileIds,0,client))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TOOLS=\"pan,wheel_zoom,box_zoom,reset,hover\"\n",
      "\n",
      "color_cycle=['red', 'green', 'blue', 'black','cyan','magenta','yellow']\n",
      "hold()\n",
      "figure()\n",
      "for datum in data:\n",
      "    for i,myFile in enumerate(export_fileIds):\n",
      "        x1 = datum[:,0][(datum[:,2]==myFile)]\n",
      "        y1 = datum[:,1][(datum[:,2]==myFile)]\n",
      "        idx = np.argsort(x1)\n",
      "        line(x1[idx],y1[idx], \n",
      "             plot_width=1000, plot_height=500,\n",
      "             line_color=color_cycle[i],\n",
      "             title='Chromatograms',\n",
      "             x_axis_label='Time (minutes)',\n",
      "             y_axis_label='Intensity')\n",
      "\n",
      "for i,myFile in enumerate(export_fileIds):\n",
      "    for j,fid in enumerate(fileInfo['fid']):\n",
      "        if fid == myFile:\n",
      "            scatter(0,0,line_color=color_cycle[i],\n",
      "                    fill_color=color_cycle[i],legend=fileInfo['name'][j])\n",
      "            \n",
      "show()\n",
      "hold('false')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "export_filenames = []\n",
      "for i,myFile in enumerate(export_fileIds):\n",
      "    for j,fid in enumerate(fileInfo['fid']):\n",
      "        if fid == myFile:\n",
      "            export_filenames.append(fileInfo['name'][j])\n",
      "            \n",
      "filename = 'output.txt'\n",
      "fid = open(filename,'wb')\n",
      "fid.write('%s\\t' % 'compound')\n",
      "for filename in export_filenames:\n",
      "    fid.write('%s\\t' % filename)\n",
      "fid.write('\\n')\n",
      "for i,datum in enumerate(data):\n",
      "    fid.write('%s\\t' % dictData[u'compounds'][i]['name'])\n",
      "    for j,myFile in enumerate(export_fileIds):\n",
      "        x1 = datum[:,0][(datum[:,2]==myFile)]\n",
      "        y1 = datum[:,1][(datum[:,2]==myFile)]\n",
      "        fid.write('%5.2f\\t' % sum(y1))        \n",
      "    fid.write('\\n')\n",
      "fid.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}